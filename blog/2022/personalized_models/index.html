<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Evolution of Personalized Models | Caleb N. Ellington</title> <meta name="author" content="Caleb N. Ellington"/> <meta name="description" content="Unifying a statistical lineage"/> <meta name="keywords" content="machine-learning, meta-learning, multitask-learning, personalized-healthcare, precision-medicine, biological-modeling, academic-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>☕️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://cnellington.github.io/blog/2022/personalized_models/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://cnellington.github.io/"><span class="font-weight-bold">Caleb</span> N. Ellington</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Evolution of Personalized Models</h1> <p class="post-meta">July 19, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/tag/math"> <i class="fas fa-hashtag fa-sm"></i> math</a>   <a href="/blog/tag/machine-learning"> <i class="fas fa-hashtag fa-sm"></i> machine-learning</a>   <a href="/blog/tag/statistics"> <i class="fas fa-hashtag fa-sm"></i> statistics</a>   <a href="/blog/tag/personalization"> <i class="fas fa-hashtag fa-sm"></i> personalization</a>     ·   <a href="/blog/category/research"> <i class="fas fa-tag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <p><em>This list is not complete, but my end goal is to make it comprehensive. If there is a model you don’t see here that belongs in the set of “principal equations” below, please drop me a line. My email can be copied using the icon on the main page.</em></p> <p>When observed data comes from highly individual, sample-specific models,</p> \[X_i \sim P(X; \theta_i)\] <p>how can we recover \(N\) sample-specific parameter estimates \(\{\widehat{\theta_i}\}_1^N\) with just \(N\) samples?</p> <p>Recently, I’ve been working on a survey of personalized modeling methods that answer this question with various assumptions about the relationships within a set models. This interesting lineage of statistics has had sporadic contributions over its lifetime, and is rarely viewed as a single family of methods. I’m writing this survey to unify this lineage and to raise awareness – especially among clinicians and biologists – that there is a suite of statistically-grounded methods for inferring personalized models that are well-aligned with our understanding of many real biological systems, while requiring little more effort to apply than classic subpopulation/cohort models.</p> <h3 id="0-subpopulation-and-cohort-models">0. Subpopulation and Cohort Models</h3> <p>First, an explanation of subpopulation and cohort models and their issues. We will assume that the parameters \(\theta\) for our model of interest have some log-likelihood function \(\ell(X; \theta)\) over the data \(X\). For some subpopulation or cohort \(c\), we can model this cohort with a generic estimator, maximizing the likelihood of the cohort model on the cohort data.</p> \[\widehat{\theta_c} = \arg\max_{\theta_c} \ell(X_c; \theta_c)\] <p>This assumes that each subpopulation or cohort is homogeneous, having the same underlying model. However, in many cases biological mechanisms are extremely heterogeneous and it would better align with our understanding if model estimates reflected the differences between samples.</p> <h1 id="personalized-models">Personalized models</h1> <p>From here onward, I <strong>very briefly</strong> outline an assumption and a principal equation that applies this assumption to recover \(N\) models from \(N\) samples. I keep these equations simple to highlight the assumption-model relationship in each case.</p> <h2 id="context-informed-models">Context-informed models</h2> <p>Context variables like time or location (which we call <em>covariates</em>) can often explain model variation.</p> <h3 id="1-classic-varying-coefficient-models">1. Classic varying-coefficient models</h3> <p>Assumption: models with similar covariates have similar parameters (more formally: parameters are smooth over covariates)</p> \[\widehat{\theta}_0, ..., \widehat{\theta}_N = \arg\max_{\theta_0, ..., \theta_N} \sum_{i, j} \frac{K(c_i, c_j)}{\sum_{k} K(c_i, c_k)} \ell(x_j; \theta_i)\] <p>Where \(K(c_i, c_j)\) is a similarity metric, usually a kernel.</p> <p>Example: <a href="https://doi.org/10.1214/09-AOAS308" target="_blank" rel="noopener noreferrer">Kolar, Mladen et al. “Estimating Time-Varying Networks.”</a></p> <h3 id="2-linear-varying-coefficient-models">2. Linear varying-coefficient models</h3> <p>Assumption: parameters vary linearly with covariates. Stronger than the classic assumption but highly interpretable. This allows the relationship between covariates and parameters to itself be parameterized.</p> \[\widehat{A} = \arg\max_A \sum_i \ell(x_i; A c_i)\] \[\widehat{\theta}_0, ..., \widehat{\theta}_N = \widehat{A} C^T\] <p>Example: <a href="https://doi.org/10.1214/aos/1017939139" target="_blank" rel="noopener noreferrer">Fan, Jianqing, and Wenyang Zhang. “Statistical Estimation in Varying Coefficient Models.”</a></p> <h3 id="3-contextualized-models">3. Contextualized Models</h3> <p>Assumption: parameters are some function of context, but make no assumption on the form of that function.</p> \[\widehat{f} = \arg \max_{f \in \mathcal{F}} \sum_i \ell(x_i; f(c_i))\] \[\widehat{\theta}_0, ..., \widehat{\theta}_N = \widehat{f}(C)\] <p><a href="https://doi.org/10.48550/arXiv.1705.10301" target="_blank" rel="noopener noreferrer">Al-Shedivat, Maruan, et al. “Contextual Explanation Networks.”</a></p> <h2 id="latent-structure-models">Latent-structure Models</h2> <p>These methods discover underlying structures in the data that guide model learning.</p> <h3 id="4-partition-models">4. Partition models</h3> <p>Assumption: parameters can be partitioned into homogeneous groups over the covariate space, but make no assumption about where these partitions occur. Partition model estimators are most often utilized to infer abrupt model changes over time.</p> \[\widehat{\theta}_0, ..., \widehat{\theta}_N = \arg\max_{\theta_0, ..., \theta_N} \sum_i \ell(x_i; \theta_i) + \sum_{i = 2}^N \text{TV}(\theta_i, \theta_{i-1})\] <p>Where the regularizaiton term might take the form \(\text{TV}(\theta_i, \theta_{i - 1}) = |\theta_i - \theta_{i-1}|\)</p> <p>Example: <a href="https://doi.org/10.1214/09-AOAS308" target="_blank" rel="noopener noreferrer">Kolar, Mladen et al. “Estimating Time-Varying Networks.”</a></p> <h2 id="context-informed-latent-structure-models">Context-informed latent-structure models</h2> <p>These methods use principals from both context-informed and latent-structure methods.</p> <h3 id="5-distance-matching-models">5. Distance-matching models</h3> <p>Assumption: there is a transformation of the context space where distance in the transformed space is equal to the similarity between models. This uses the similar-context-similar-parameter assumption from varying-coefficient models, but also imposes a different-context-different-parameter assumption that doesn’t directly follow the first.</p> \[\widehat{\theta}_0, ..., \widehat{\theta}_N = \arg\max_{\theta_0, ..., \theta_N, D} \sum_{i=0}^N \prod_{j=0 s.t. D(c_i, c_j) &lt; d}^N \ell(x_j; \theta_i) P(\theta_i ; \theta_j)\] <p>Where \(D(c_i, c_j)\) is a learnable distance metric.</p> <p>Example: <a href="https://doi.org/10.48550/arXiv.1910.06939" target="_blank" rel="noopener noreferrer">Lengerich, Benjamin, et al. “Learning Sample-Specific Models with Low-Rank Personalized Regression.”</a></p> <p>Thanks for reading!</p> <p><em>This list is not complete, but my end goal is to make it comprehensive. If there is a model you don’t see here that belongs in the set of “principal equations” below, please drop me a line. My email can be copied using the icon on the main page.</em></p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Caleb N. Ellington. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Last updated: December 23, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>